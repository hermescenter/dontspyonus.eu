---
title: "Le Sendbox ed i loro problemi"
subtitle: "Una semplice spiegazione sul perchè il sistema previsot dall'AIAct non sarà sufficente a tutelarci"
---

# Una _sandbox_ è un ambiente di prova nella quale una compagnia che vuole rilasciare un prodotto basato sull'AI, deve utilizzare nel caso il suo sistema di AI possa comportare dei rischi.

# Il sistema di test consiste in computer dedicati a questo scopo, che non saranno connessi al servizio offerto pubblicamente, e non processeranno dati di utenti reali.

# E' un sistema pensato perchè le autorità e chi svolge ricerca sull'affidabilità dei sistemi di intelligenza artificiale possano verificare la bontà della tecnologia.

# Questo, in teoria, dovrebbe servire a mitigare problemi, perchè solo i sistemi che passano i controlli dovrebbero essere approvati.

# Anche se questa è la teoria, la pratica è molto diversa. Per prima cosa i sistemi di intelligenza artificiale, anche detti "esperti" sono tali perchè si adattano all'utilizzo. Pertanto la casistica del comportamento indivuale non sarà mai simulabile da chi svolge i test.

# In parole povere: se gli analisti sono degli ingenieri che lavorano a Roma, non potranno mai simulare di essere delle Casalinghe di Voghera, e valideranno un sistema senza averlo provato in tutte le sue condizioni. Cosa comunque impossibile, perchè`*` un sistema di AI si adatta al soggetto che lo utilizza.

\* normalmente è così, ma potrebbero anche esistere sistemi di AI che trattano tutti gli utenti allo stesso modo. Sono una rarità, e ad esempio anche chatGPT personalizza le risposte sulla base delle interazioni precedenti.

# Se poi pensiamo allo scandatlo Dieselgate della Volkswagen, vediamo come degli igenieri si fossero dedicati ad ingannare sistemi di test, ovvero, quando la tecnologia viene eseguita nel sistema di test si comporta in modo conforme alle leggi, quando è in produzione, no. Non è difficile pensare che compagnie senza etica facciano altrettanto nel digitle.


